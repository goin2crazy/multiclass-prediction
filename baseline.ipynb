{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60893,"databundleVersionId":7000181,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import modules\nimport pandas as pd \nimport numpy as np \n\nfrom sklearn.preprocessing import (PowerTransformer, \n                                   LabelEncoder)\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-29T20:52:41.743591Z","iopub.execute_input":"2023-12-29T20:52:41.744661Z","iopub.status.idle":"2023-12-29T20:52:41.751487Z","shell.execute_reply.started":"2023-12-29T20:52:41.744609Z","shell.execute_reply":"2023-12-29T20:52:41.749856Z"},"trusted":true},"execution_count":288,"outputs":[]},{"cell_type":"code","source":"# init global variables\ntrain_path = '/kaggle/input/playground-series-s3e26/train.csv'\ntest_path = '/kaggle/input/playground-series-s3e26/test.csv'","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:41.824841Z","iopub.execute_input":"2023-12-29T20:52:41.825272Z","iopub.status.idle":"2023-12-29T20:52:41.830855Z","shell.execute_reply.started":"2023-12-29T20:52:41.825235Z","shell.execute_reply":"2023-12-29T20:52:41.829465Z"},"trusted":true},"execution_count":289,"outputs":[]},{"cell_type":"code","source":"# read datasets\ntrain_df = pd.read_csv(train_path)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:41.925432Z","iopub.execute_input":"2023-12-29T20:52:41.925915Z","iopub.status.idle":"2023-12-29T20:52:41.983490Z","shell.execute_reply.started":"2023-12-29T20:52:41.925876Z","shell.execute_reply":"2023-12-29T20:52:41.982282Z"},"trusted":true},"execution_count":290,"outputs":[{"execution_count":290,"output_type":"execute_result","data":{"text/plain":"   id  N_Days             Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n0   0     999  D-penicillamine  21532   M       N            N       N     N   \n1   1    2574          Placebo  19237   F       N            N       N     N   \n2   2    3428          Placebo  13727   F       N            Y       Y     Y   \n3   3    2576          Placebo  18460   F       N            N       N     N   \n4   4     788          Placebo  16658   F       N            Y       N     N   \n\n   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n0        2.3        316.0     3.35   172.0    1601.0  179.80           63.0   \n1        0.9        364.0     3.54    63.0    1440.0  134.85           88.0   \n2        3.3        299.0     3.55   131.0    1029.0  119.35           50.0   \n3        0.6        256.0     3.50    58.0    1653.0   71.30           96.0   \n4        1.1        346.0     3.65    63.0    1181.0  125.55           96.0   \n\n   Platelets  Prothrombin  Stage Status  \n0      394.0          9.7    3.0      D  \n1      361.0         11.0    3.0      C  \n2      199.0         11.7    4.0      D  \n3      269.0         10.7    3.0      C  \n4      298.0         10.6    4.0      C  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>N_Days</th>\n      <th>Drug</th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Ascites</th>\n      <th>Hepatomegaly</th>\n      <th>Spiders</th>\n      <th>Edema</th>\n      <th>Bilirubin</th>\n      <th>Cholesterol</th>\n      <th>Albumin</th>\n      <th>Copper</th>\n      <th>Alk_Phos</th>\n      <th>SGOT</th>\n      <th>Tryglicerides</th>\n      <th>Platelets</th>\n      <th>Prothrombin</th>\n      <th>Stage</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>999</td>\n      <td>D-penicillamine</td>\n      <td>21532</td>\n      <td>M</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>2.3</td>\n      <td>316.0</td>\n      <td>3.35</td>\n      <td>172.0</td>\n      <td>1601.0</td>\n      <td>179.80</td>\n      <td>63.0</td>\n      <td>394.0</td>\n      <td>9.7</td>\n      <td>3.0</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2574</td>\n      <td>Placebo</td>\n      <td>19237</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.9</td>\n      <td>364.0</td>\n      <td>3.54</td>\n      <td>63.0</td>\n      <td>1440.0</td>\n      <td>134.85</td>\n      <td>88.0</td>\n      <td>361.0</td>\n      <td>11.0</td>\n      <td>3.0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3428</td>\n      <td>Placebo</td>\n      <td>13727</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>Y</td>\n      <td>3.3</td>\n      <td>299.0</td>\n      <td>3.55</td>\n      <td>131.0</td>\n      <td>1029.0</td>\n      <td>119.35</td>\n      <td>50.0</td>\n      <td>199.0</td>\n      <td>11.7</td>\n      <td>4.0</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2576</td>\n      <td>Placebo</td>\n      <td>18460</td>\n      <td>F</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>N</td>\n      <td>0.6</td>\n      <td>256.0</td>\n      <td>3.50</td>\n      <td>58.0</td>\n      <td>1653.0</td>\n      <td>71.30</td>\n      <td>96.0</td>\n      <td>269.0</td>\n      <td>10.7</td>\n      <td>3.0</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>788</td>\n      <td>Placebo</td>\n      <td>16658</td>\n      <td>F</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>N</td>\n      <td>N</td>\n      <td>1.1</td>\n      <td>346.0</td>\n      <td>3.65</td>\n      <td>63.0</td>\n      <td>1181.0</td>\n      <td>125.55</td>\n      <td>96.0</td>\n      <td>298.0</td>\n      <td>10.6</td>\n      <td>4.0</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class GetDummies:\n    def __init__(self, name='category', fit=None):\n        self.columns = None\n        self.fillna_value = None\n        self.name = name\n        \n        if fit is not None: \n            self.fit(fit)\n            self.first_fit = True\n        else: \n            self.first_fit = False\n            \n    def fit(self, series):\n        self.columns = series.unique()\n        self.first_fit = True\n\n    def set_fillna(self, v):\n        self.fillna_value = v\n\n    def lst_transform(self, data):\n        result = []\n\n        for val in data:\n            variants = [0] * len(self.columns)\n            not_founded = True\n\n            for i, col in enumerate(self.columns):\n                if val == col:\n                    variants[i] = 1\n                    result.append(variants)\n                    not_founded = False\n                    break\n\n            if not_founded:\n                result.append([self.fillna_value] * len(self.columns))\n        return result\n\n    def transform(self, data):\n        tr_lst = self.lst_transform(data)\n\n        df_data = {f'{self.name}_{col}': [] for col in self.columns}\n\n        for tr in tr_lst:\n            for col, val in zip(self.columns, tr):\n                df_data[f'{self.name}_{col}'].append(val)\n\n        return pd.DataFrame(df_data)\n\n    def __call__(self, data):\n        if self.first_fit == False: \n            self.fit(data)\n            self.first_fit = True\n            \n        return self.transform(data.to_list())","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:41.991315Z","iopub.execute_input":"2023-12-29T20:52:41.991736Z","iopub.status.idle":"2023-12-29T20:52:42.005498Z","shell.execute_reply.started":"2023-12-29T20:52:41.991700Z","shell.execute_reply":"2023-12-29T20:52:42.004541Z"},"trusted":true},"execution_count":291,"outputs":[]},{"cell_type":"code","source":"false_true_cols = [\"Sex\", \"Ascites\", \"Spiders\", \"Edema\", \"Hepatomegaly\"]\n\ndrug_enc = GetDummies(name = \"drug\", fit = train_df['Drug'])\n\nstatus_enc = GetDummies(name = \"status\", fit = train_df['Status'])\n\ndef false_true_cols_(df) -> pd.DataFrame: \n    for i in false_true_cols: \n        if i == 'Sex': \n            df[i] = df[i].apply(lambda l: 1 if l == 'F' else 0)\n        else:  \n            df[i] = df[i].apply(lambda l: 1 if l == 'N' else 0)\n    return df \n\ndef preprocess_y(df): \n    return status_enc(df)\n\ndef categorical_cols_(df) -> pd.DataFrame: \n    drug_dummies = drug_enc(df['Drug'])\n    df = df.drop('Drug', axis=1)\n    df = pd.concat([drug_dummies, df], axis=1)\n    \n    return df\n\ndef transform_numeric_cols_(df) -> pd.DataFrame:\n    ...\n    return df\n\ndef preprocess_x(df) -> pd.DataFrame: \n    df = df.copy()\n    \n    df = df.drop('id', axis=1)\n    df = transform_numeric_cols_(df)\n    df = false_true_cols_(df)\n    df = categorical_cols_(df)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.057541Z","iopub.execute_input":"2023-12-29T20:52:42.058036Z","iopub.status.idle":"2023-12-29T20:52:42.073410Z","shell.execute_reply.started":"2023-12-29T20:52:42.057999Z","shell.execute_reply":"2023-12-29T20:52:42.072092Z"},"trusted":true},"execution_count":292,"outputs":[]},{"cell_type":"code","source":"X = preprocess_x(train_df.drop(['Status'], axis=1))\ny = preprocess_y(train_df['Status'])\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size = 0.8)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.131936Z","iopub.execute_input":"2023-12-29T20:52:42.132365Z","iopub.status.idle":"2023-12-29T20:52:42.276368Z","shell.execute_reply.started":"2023-12-29T20:52:42.132332Z","shell.execute_reply":"2023-12-29T20:52:42.275069Z"},"trusted":true},"execution_count":293,"outputs":[]},{"cell_type":"code","source":"from tensorflow.data import Dataset\nimport tensorflow.keras.layers as l\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import Model\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.278343Z","iopub.execute_input":"2023-12-29T20:52:42.278680Z","iopub.status.idle":"2023-12-29T20:52:42.284499Z","shell.execute_reply.started":"2023-12-29T20:52:42.278650Z","shell.execute_reply":"2023-12-29T20:52:42.283145Z"},"trusted":true},"execution_count":294,"outputs":[]},{"cell_type":"code","source":"def build_dataset(X, y, batch_size = 16, shuffle = True, prefetch = True): \n    dataset = Dataset.from_tensor_slices((\n        X, \n        y['status_C'], \n        y['status_CL'], \n        y['status_D'])\n    ).batch(batch_size)\n    \n    if shuffle: \n        dataset = dataset.shuffle(16)\n        \n    if prefetch: \n        dataset = dataset.prefetch(tf.data.AUTOTUNE)\n        \n    return dataset ","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.285926Z","iopub.execute_input":"2023-12-29T20:52:42.286475Z","iopub.status.idle":"2023-12-29T20:52:42.297433Z","shell.execute_reply.started":"2023-12-29T20:52:42.286432Z","shell.execute_reply":"2023-12-29T20:52:42.296109Z"},"trusted":true},"execution_count":295,"outputs":[]},{"cell_type":"code","source":"def build_model(input_shape): \n    inputs = l.Input(input_shape, name='input')\n    \n    inputs = l.Dropout(0.3)(inputs)\n    x = l.Dense(64, activation = 'linear', name='hidden')(inputs)\n    x = l.BatchNormalization()(x)\n    outputs = l.Dense(1, activation='sigmoid', name = 'output')(x)\n    \n    return Model(inputs, outputs)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.329417Z","iopub.execute_input":"2023-12-29T20:52:42.329865Z","iopub.status.idle":"2023-12-29T20:52:42.337025Z","shell.execute_reply.started":"2023-12-29T20:52:42.329831Z","shell.execute_reply":"2023-12-29T20:52:42.335732Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"class MainModel(Model): \n    def __init__(self, input_shape = (19)): \n        super().__init__()\n        \n        self.cmodel = build_model(input_shape)\n        self.clmodel = build_model(input_shape)        \n        self.dmodel = build_model(input_shape)        \n        \n    def compile(self): \n        super().compile()\n        \n        self.c_optimizer = Adam(lr = 1e-3)\n        self.cl_optimizer = Adam(lr= 1e-3)        \n        self.d_optimizer = Adam(lr = 1e-3)        \n        \n        self.loss_fn = BinaryCrossentropy()\n        \n    def train_step(self, batch_data): \n        x, c, cl, d = batch_data\n        \n        with tf.GradientTape(persistent = True) as tape: \n            c_ = self.cmodel(x, training = True)\n            cl_ = self.clmodel(x, training = True)            \n            d_ = self.dmodel(x, training=  True)            \n            \n            c_loss = self.loss_fn(c, c_)\n            cl_loss = self.loss_fn(cl, cl_)            \n            d_loss = self.loss_fn(d, d_)   \n            \n            total = c_loss + cl_loss + d_loss\n            \n        c_grads = tape.gradient(c_loss, self.cmodel.trainable_variables)\n        cl_grads = tape.gradient(cl_loss, self.clmodel.trainable_variables)        \n        d_grads = tape.gradient(d_loss, self.dmodel.trainable_variables)        \n        \n        self.c_optimizer.apply_gradients(zip(c_grads, self.cmodel.trainable_variables))\n        self.cl_optimizer.apply_gradients(zip(cl_grads, self.clmodel.trainable_variables))        \n        self.d_optimizer.apply_gradients(zip(d_grads, self.dmodel.trainable_variables))     \n        \n        return {'loss': total}\n    \n    def test_step(self, batch_data): \n        x, c, cl, d = batch_data\n        \n        c_ = self.cmodel(x)\n        cl_ = self.clmodel(x)            \n        d_ = self.dmodel(x)            \n\n        c_loss = self.loss_fn(c, c_)\n        cl_loss = self.loss_fn(cl, cl_)            \n        d_loss = self.loss_fn(d, d_)   \n\n        total = c_loss + cl_loss + d_loss\n        \n        return {'loss': total}","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.380525Z","iopub.execute_input":"2023-12-29T20:52:42.380962Z","iopub.status.idle":"2023-12-29T20:52:42.398399Z","shell.execute_reply.started":"2023-12-29T20:52:42.380926Z","shell.execute_reply":"2023-12-29T20:52:42.397188Z"},"trusted":true},"execution_count":297,"outputs":[]},{"cell_type":"code","source":"train_dataset = build_dataset(X_train, y_train, batch_size = 8)\nval_dataset = build_dataset(X_val, y_val, batch_size = 16)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.422460Z","iopub.execute_input":"2023-12-29T20:52:42.422886Z","iopub.status.idle":"2023-12-29T20:52:42.470496Z","shell.execute_reply.started":"2023-12-29T20:52:42.422854Z","shell.execute_reply":"2023-12-29T20:52:42.469225Z"},"trusted":true},"execution_count":298,"outputs":[]},{"cell_type":"code","source":"model = MainModel()\nmodel.compile()\n\nes = tf.keras.callbacks.EarlyStopping(patience = 60, min_delta = 1e-5, restore_best_weights = True)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.474407Z","iopub.execute_input":"2023-12-29T20:52:42.474896Z","iopub.status.idle":"2023-12-29T20:52:42.660860Z","shell.execute_reply.started":"2023-12-29T20:52:42.474850Z","shell.execute_reply":"2023-12-29T20:52:42.659859Z"},"trusted":true},"execution_count":299,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset, epochs = 100, validation_data = val_dataset, callbacks = [es])","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:52:42.663447Z","iopub.execute_input":"2023-12-29T20:52:42.663884Z","iopub.status.idle":"2023-12-29T20:55:39.688137Z","shell.execute_reply.started":"2023-12-29T20:52:42.663843Z","shell.execute_reply":"2023-12-29T20:55:39.686890Z"},"trusted":true},"execution_count":300,"outputs":[{"name":"stdout","text":"Epoch 1/100\n791/791 [==============================] - 5s 3ms/step - loss: 1.3330 - val_loss: 1.8257\nEpoch 2/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1946 - val_loss: 1.1325\nEpoch 3/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1799 - val_loss: 0.8081\nEpoch 4/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1726 - val_loss: 0.6942\nEpoch 5/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1670 - val_loss: 0.9188\nEpoch 6/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1584 - val_loss: 1.3226\nEpoch 7/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1477 - val_loss: 1.5972\nEpoch 8/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1416 - val_loss: 1.4355\nEpoch 9/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1345 - val_loss: 2.1812\nEpoch 10/100\n791/791 [==============================] - 3s 3ms/step - loss: 1.1240 - val_loss: 2.1731\nEpoch 11/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1196 - val_loss: 1.0151\nEpoch 12/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1084 - val_loss: 0.6111\nEpoch 13/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1021 - val_loss: 1.5033\nEpoch 14/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.1011 - val_loss: 1.6782\nEpoch 15/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0889 - val_loss: 1.9051\nEpoch 16/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0902 - val_loss: 1.4766\nEpoch 17/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0885 - val_loss: 1.5373\nEpoch 18/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0859 - val_loss: 0.7974\nEpoch 19/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0825 - val_loss: 0.8630\nEpoch 20/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0792 - val_loss: 0.8621\nEpoch 21/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0780 - val_loss: 1.0100\nEpoch 22/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0795 - val_loss: 2.3674\nEpoch 23/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0718 - val_loss: 1.6823\nEpoch 24/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0718 - val_loss: 2.5560\nEpoch 25/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0720 - val_loss: 0.9769\nEpoch 26/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0685 - val_loss: 1.4493\nEpoch 27/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0643 - val_loss: 1.1285\nEpoch 28/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0665 - val_loss: 1.6184\nEpoch 29/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0639 - val_loss: 1.1116\nEpoch 30/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0612 - val_loss: 1.1204\nEpoch 31/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0616 - val_loss: 1.4468\nEpoch 32/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0613 - val_loss: 1.3056\nEpoch 33/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0640 - val_loss: 1.0852\nEpoch 34/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0592 - val_loss: 0.9415\nEpoch 35/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0593 - val_loss: 0.8244\nEpoch 36/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0633 - val_loss: 1.4157\nEpoch 37/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0537 - val_loss: 1.0321\nEpoch 38/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0566 - val_loss: 1.3819\nEpoch 39/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0589 - val_loss: 1.5370\nEpoch 40/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0525 - val_loss: 0.8496\nEpoch 41/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0520 - val_loss: 1.8558\nEpoch 42/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0562 - val_loss: 1.2525\nEpoch 43/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0546 - val_loss: 2.1989\nEpoch 44/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0566 - val_loss: 0.9094\nEpoch 45/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0553 - val_loss: 0.7954\nEpoch 46/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0488 - val_loss: 2.2118\nEpoch 47/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0465 - val_loss: 2.1482\nEpoch 48/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0505 - val_loss: 1.0885\nEpoch 49/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0507 - val_loss: 0.8571\nEpoch 50/100\n791/791 [==============================] - 3s 3ms/step - loss: 1.0514 - val_loss: 2.7596\nEpoch 51/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0528 - val_loss: 1.3927\nEpoch 52/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0513 - val_loss: 0.8761\nEpoch 53/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0506 - val_loss: 0.6603\nEpoch 54/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0467 - val_loss: 2.8153\nEpoch 55/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0521 - val_loss: 2.3439\nEpoch 56/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0466 - val_loss: 1.6270\nEpoch 57/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0473 - val_loss: 1.6195\nEpoch 58/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0436 - val_loss: 2.4841\nEpoch 59/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0460 - val_loss: 1.7216\nEpoch 60/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0461 - val_loss: 1.2817\nEpoch 61/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0463 - val_loss: 0.7965\nEpoch 62/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0437 - val_loss: 1.5635\nEpoch 63/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0425 - val_loss: 0.7088\nEpoch 64/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0411 - val_loss: 0.8299\nEpoch 65/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0434 - val_loss: 1.1028\nEpoch 66/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0449 - val_loss: 1.0719\nEpoch 67/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0401 - val_loss: 2.4567\nEpoch 68/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0408 - val_loss: 0.7259\nEpoch 69/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0389 - val_loss: 0.8440\nEpoch 70/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0413 - val_loss: 0.7898\nEpoch 71/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0410 - val_loss: 1.6725\nEpoch 72/100\n791/791 [==============================] - 2s 3ms/step - loss: 1.0384 - val_loss: 0.8791\n","output_type":"stream"},{"execution_count":300,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d51123f8b20>"},"metadata":{}}]},{"cell_type":"code","source":"test_df = pd.read_csv(test_path)\ntest_X = preprocess_x(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:56:24.783920Z","iopub.execute_input":"2023-12-29T20:56:24.784367Z","iopub.status.idle":"2023-12-29T20:56:24.866336Z","shell.execute_reply.started":"2023-12-29T20:56:24.784337Z","shell.execute_reply":"2023-12-29T20:56:24.865072Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"code","source":"c_prediction = model.cmodel(test_X.values)\ncl_prediction = model.clmodel(test_X.values)\nd_prediction = model.dmodel(test_X.values)\n\ndf_data = {\n          'Status_D': [i[0] for i in d_prediction.numpy()], \n    'Status_C': [i[0] for i in c_prediction.numpy()], \n          'Status_CL': [i[0] for i in cl_prediction.numpy()]} \n","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:56:29.971960Z","iopub.execute_input":"2023-12-29T20:56:29.972400Z","iopub.status.idle":"2023-12-29T20:56:30.011139Z","shell.execute_reply.started":"2023-12-29T20:56:29.972363Z","shell.execute_reply":"2023-12-29T20:56:30.009906Z"},"trusted":true},"execution_count":306,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test_df['id'], **df_data})","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:56:35.096011Z","iopub.execute_input":"2023-12-29T20:56:35.096435Z","iopub.status.idle":"2023-12-29T20:56:35.111007Z","shell.execute_reply.started":"2023-12-29T20:56:35.096402Z","shell.execute_reply":"2023-12-29T20:56:35.109701Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-29T20:56:42.748834Z","iopub.execute_input":"2023-12-29T20:56:42.749564Z","iopub.status.idle":"2023-12-29T20:56:42.791409Z","shell.execute_reply.started":"2023-12-29T20:56:42.749505Z","shell.execute_reply":"2023-12-29T20:56:42.790061Z"},"trusted":true},"execution_count":308,"outputs":[]}]}